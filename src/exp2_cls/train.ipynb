{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f6ae560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cfg='configs/vit_large_384.yaml', ckpt_dir='checkpoints', frac=1, folds=[0, 1, 2, 3, 4])\n",
      "{'model_name': 'vit_large_patch14_clip_336.openai_ft_in12k_in1k', 'workers': 8, 'image_size': 384, 'batch_size': 96, 'init_lr': 1e-05, 'epochs': 15, 'mixup': True, 'ema_decay': 0.995, 'epochs_for_final_submission': 4}\n",
      "****************************** Fold 0 ******************************\n",
      "TRAIN: 441842 | VALID: 209746\n",
      "Fold: 0 | Epoch 0 | train loss: 0.01796 | val_auc: 0.77728 | ema_val_auc: 0.79049\n",
      "val auc improved from 0.00000 to 0.79049 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold0.pt\n",
      "Fold: 0 | Epoch 1 | train loss: 0.01387 | val_auc: 0.81334 | ema_val_auc: 0.82811\n",
      "val auc improved from 0.79049 to 0.82811 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold0.pt\n",
      "Fold: 0 | Epoch 2 | train loss: 0.01192 | val_auc: 0.83567 | ema_val_auc: 0.84418\n",
      "val auc improved from 0.82811 to 0.84418 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold0.pt\n",
      "Fold: 0 | Epoch 3 | train loss: 0.01050 | val_auc: 0.82978 | ema_val_auc: 0.84415\n",
      "Fold: 0 | Epoch 4 | train loss: 0.00900 | val_auc: 0.83643 | ema_val_auc: 0.85561\n",
      "val auc improved from 0.84418 to 0.85561 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold0.pt\n",
      "Fold: 0 | Epoch 5 | train loss: 0.00770 | val_auc: 0.84274 | ema_val_auc: 0.84610\n",
      "Fold: 0 | Epoch 6 | train loss: 0.00661 | val_auc: 0.82928 | ema_val_auc: 0.84199\n",
      "Fold: 0 | Epoch 7 | train loss: 0.00575 | val_auc: 0.83682 | ema_val_auc: 0.84353\n",
      "Fold: 0 | Epoch 8 | train loss: 0.00522 | val_auc: 0.84174 | ema_val_auc: 0.84339\n",
      "Fold: 0 | Epoch 9 | train loss: 0.00475 | val_auc: 0.84372 | ema_val_auc: 0.84195\n",
      "Fold: 0 | Epoch 10 | train loss: 0.00441 | val_auc: 0.83908 | ema_val_auc: 0.83960\n",
      "Fold: 0 | Epoch 11 | train loss: 0.00419 | val_auc: 0.83941 | ema_val_auc: 0.83956\n",
      "Fold: 0 | Epoch 12 | train loss: 0.00426 | val_auc: 0.84146 | ema_val_auc: 0.84102\n",
      "Fold: 0 | Epoch 13 | train loss: 0.00419 | val_auc: 0.84146 | ema_val_auc: 0.84145\n",
      "Fold: 0 | Epoch 14 | train loss: 0.00408 | val_auc: 0.84288 | ema_val_auc: 0.84304\n",
      "****************************** Fold 1 ******************************\n",
      "TRAIN: 453316 | VALID: 198113\n",
      "Fold: 1 | Epoch 0 | train loss: 0.01742 | val_auc: 0.78199 | ema_val_auc: 0.78048\n",
      "val auc improved from 0.00000 to 0.78199 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold1.pt\n",
      "Fold: 1 | Epoch 1 | train loss: 0.01345 | val_auc: 0.81587 | ema_val_auc: 0.82697\n",
      "val auc improved from 0.78199 to 0.82697 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold1.pt\n",
      "Fold: 1 | Epoch 2 | train loss: 0.01172 | val_auc: 0.83080 | ema_val_auc: 0.85066\n",
      "val auc improved from 0.82697 to 0.85066 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold1.pt\n",
      "Fold: 1 | Epoch 3 | train loss: 0.01020 | val_auc: 0.83334 | ema_val_auc: 0.85171\n",
      "val auc improved from 0.85066 to 0.85171 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold1.pt\n",
      "Fold: 1 | Epoch 4 | train loss: 0.00872 | val_auc: 0.83516 | ema_val_auc: 0.85241\n",
      "val auc improved from 0.85171 to 0.85241 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold1.pt\n",
      "Fold: 1 | Epoch 5 | train loss: 0.00768 | val_auc: 0.84406 | ema_val_auc: 0.85720\n",
      "val auc improved from 0.85241 to 0.85720 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold1.pt\n",
      "Fold: 1 | Epoch 6 | train loss: 0.00653 | val_auc: 0.84907 | ema_val_auc: 0.85190\n",
      "Fold: 1 | Epoch 7 | train loss: 0.00580 | val_auc: 0.84759 | ema_val_auc: 0.85334\n",
      "Fold: 1 | Epoch 8 | train loss: 0.00515 | val_auc: 0.84280 | ema_val_auc: 0.85029\n",
      "Fold: 1 | Epoch 9 | train loss: 0.00459 | val_auc: 0.84801 | ema_val_auc: 0.84939\n",
      "Fold: 1 | Epoch 10 | train loss: 0.00444 | val_auc: 0.84460 | ema_val_auc: 0.84885\n",
      "Fold: 1 | Epoch 11 | train loss: 0.00415 | val_auc: 0.85019 | ema_val_auc: 0.85109\n",
      "Fold: 1 | Epoch 12 | train loss: 0.00400 | val_auc: 0.85261 | ema_val_auc: 0.85215\n",
      "Fold: 1 | Epoch 13 | train loss: 0.00414 | val_auc: 0.85261 | ema_val_auc: 0.85258\n",
      "Fold: 1 | Epoch 14 | train loss: 0.00428 | val_auc: 0.85261 | ema_val_auc: 0.85301\n",
      "****************************** Fold 2 ******************************\n",
      "TRAIN: 441186 | VALID: 203375\n",
      "Fold: 2 | Epoch 0 | train loss: 0.01798 | val_auc: 0.78241 | ema_val_auc: 0.78824\n",
      "val auc improved from 0.00000 to 0.78824 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold2.pt\n",
      "Fold: 2 | Epoch 1 | train loss: 0.01391 | val_auc: 0.82087 | ema_val_auc: 0.83073\n",
      "val auc improved from 0.78824 to 0.83073 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold2.pt\n",
      "Fold: 2 | Epoch 2 | train loss: 0.01205 | val_auc: 0.81403 | ema_val_auc: 0.84303\n",
      "val auc improved from 0.83073 to 0.84303 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold2.pt\n",
      "Fold: 2 | Epoch 3 | train loss: 0.01041 | val_auc: 0.83295 | ema_val_auc: 0.84759\n",
      "val auc improved from 0.84303 to 0.84759 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold2.pt\n",
      "Fold: 2 | Epoch 4 | train loss: 0.00880 | val_auc: 0.82827 | ema_val_auc: 0.84727\n",
      "Fold: 2 | Epoch 5 | train loss: 0.00764 | val_auc: 0.83813 | ema_val_auc: 0.84920\n",
      "val auc improved from 0.84759 to 0.84920 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold2.pt\n",
      "Fold: 2 | Epoch 6 | train loss: 0.00657 | val_auc: 0.83599 | ema_val_auc: 0.84754\n",
      "Fold: 2 | Epoch 7 | train loss: 0.00577 | val_auc: 0.84031 | ema_val_auc: 0.84875\n",
      "Fold: 2 | Epoch 8 | train loss: 0.00517 | val_auc: 0.83361 | ema_val_auc: 0.84110\n",
      "Fold: 2 | Epoch 9 | train loss: 0.00462 | val_auc: 0.84103 | ema_val_auc: 0.84562\n",
      "Fold: 2 | Epoch 10 | train loss: 0.00449 | val_auc: 0.84567 | ema_val_auc: 0.84636\n",
      "Fold: 2 | Epoch 11 | train loss: 0.00413 | val_auc: 0.84325 | ema_val_auc: 0.84366\n",
      "Fold: 2 | Epoch 12 | train loss: 0.00416 | val_auc: 0.84492 | ema_val_auc: 0.84506\n",
      "Fold: 2 | Epoch 13 | train loss: 0.00417 | val_auc: 0.84492 | ema_val_auc: 0.84494\n",
      "Fold: 2 | Epoch 14 | train loss: 0.00392 | val_auc: 0.84553 | ema_val_auc: 0.84585\n",
      "****************************** Fold 3 ******************************\n",
      "TRAIN: 443849 | VALID: 207682\n",
      "Fold: 3 | Epoch 0 | train loss: 0.01754 | val_auc: 0.78637 | ema_val_auc: 0.79623\n",
      "val auc improved from 0.00000 to 0.79623 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold3.pt\n",
      "Fold: 3 | Epoch 1 | train loss: 0.01362 | val_auc: 0.82761 | ema_val_auc: 0.84869\n",
      "val auc improved from 0.79623 to 0.84869 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold3.pt\n",
      "Fold: 3 | Epoch 2 | train loss: 0.01164 | val_auc: 0.82500 | ema_val_auc: 0.84361\n",
      "Fold: 3 | Epoch 3 | train loss: 0.01014 | val_auc: 0.83796 | ema_val_auc: 0.85127\n",
      "val auc improved from 0.84869 to 0.85127 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold3.pt\n",
      "Fold: 3 | Epoch 4 | train loss: 0.00862 | val_auc: 0.83980 | ema_val_auc: 0.85199\n",
      "val auc improved from 0.85127 to 0.85199 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold3.pt\n",
      "Fold: 3 | Epoch 5 | train loss: 0.00742 | val_auc: 0.84275 | ema_val_auc: 0.85027\n",
      "Fold: 3 | Epoch 6 | train loss: 0.00640 | val_auc: 0.84387 | ema_val_auc: 0.84727\n",
      "Fold: 3 | Epoch 7 | train loss: 0.00558 | val_auc: 0.84148 | ema_val_auc: 0.84804\n",
      "Fold: 3 | Epoch 8 | train loss: 0.00505 | val_auc: 0.84771 | ema_val_auc: 0.85351\n",
      "val auc improved from 0.85199 to 0.85351 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold3.pt\n",
      "Fold: 3 | Epoch 9 | train loss: 0.00453 | val_auc: 0.84870 | ema_val_auc: 0.85125\n",
      "Fold: 3 | Epoch 10 | train loss: 0.00428 | val_auc: 0.84018 | ema_val_auc: 0.84237\n",
      "Fold: 3 | Epoch 11 | train loss: 0.00396 | val_auc: 0.84221 | ema_val_auc: 0.84349\n",
      "Fold: 3 | Epoch 12 | train loss: 0.00406 | val_auc: 0.84490 | ema_val_auc: 0.84484\n",
      "Fold: 3 | Epoch 13 | train loss: 0.00390 | val_auc: 0.84490 | ema_val_auc: 0.84494\n",
      "Fold: 3 | Epoch 14 | train loss: 0.00388 | val_auc: 0.84437 | ema_val_auc: 0.84423\n",
      "****************************** Fold 4 ******************************\n",
      "TRAIN: 439595 | VALID: 209895\n",
      "Fold: 4 | Epoch 0 | train loss: 0.01830 | val_auc: 0.75005 | ema_val_auc: 0.77886\n",
      "val auc improved from 0.00000 to 0.77886 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold4.pt\n",
      "Fold: 4 | Epoch 1 | train loss: 0.01407 | val_auc: 0.79642 | ema_val_auc: 0.81847\n",
      "val auc improved from 0.77886 to 0.81847 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold4.pt\n",
      "Fold: 4 | Epoch 2 | train loss: 0.01221 | val_auc: 0.80513 | ema_val_auc: 0.82335\n",
      "val auc improved from 0.81847 to 0.82335 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold4.pt\n",
      "Fold: 4 | Epoch 3 | train loss: 0.01055 | val_auc: 0.81923 | ema_val_auc: 0.83479\n",
      "val auc improved from 0.82335 to 0.83479 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold4.pt\n",
      "Fold: 4 | Epoch 4 | train loss: 0.00892 | val_auc: 0.82764 | ema_val_auc: 0.84272\n",
      "val auc improved from 0.83479 to 0.84272 saving model to checkpoints/vit_large_patch14_clip_336.openai_ft_in12k_in1k_384_fold4.pt\n",
      "Fold: 4 | Epoch 5 | train loss: 0.00778 | val_auc: 0.82819 | ema_val_auc: 0.83601\n",
      "Fold: 4 | Epoch 6 | train loss: 0.00677 | val_auc: 0.83392 | ema_val_auc: 0.83350\n",
      "Fold: 4 | Epoch 7 | train loss: 0.00569 | val_auc: 0.82616 | ema_val_auc: 0.83264\n",
      "Fold: 4 | Epoch 8 | train loss: 0.00519 | val_auc: 0.83148 | ema_val_auc: 0.82994\n",
      "Fold: 4 | Epoch 9 | train loss: 0.00469 | val_auc: 0.82820 | ema_val_auc: 0.83339\n",
      "Fold: 4 | Epoch 10 | train loss: 0.00443 | val_auc: 0.82943 | ema_val_auc: 0.83151\n",
      "Fold: 4 | Epoch 11 | train loss: 0.00400 | val_auc: 0.83053 | ema_val_auc: 0.82967\n",
      "Fold: 4 | Epoch 12 | train loss: 0.00412 | val_auc: 0.83131 | ema_val_auc: 0.83176\n",
      "Fold: 4 | Epoch 13 | train loss: 0.00411 | val_auc: 0.83131 | ema_val_auc: 0.83138\n",
      "Fold: 4 | Epoch 14 | train loss: 0.00388 | val_auc: 0.82969 | ema_val_auc: 0.83022\n"
     ]
    }
   ],
   "source": [
    "!python train_5folds.py --cfg configs/vit_large_384.yaml    ### for label cleaning in exp4 and exp5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1805558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cfg='configs/vit_large_384.yaml', ckpt_dir='checkpoints', folds=[0, 1, 2, 3, 4], pred_dir='predictions', crop_ratio=1, hflip=False)\n",
      "{'model_name': 'vit_large_patch14_clip_336.openai_ft_in12k_in1k', 'workers': 8, 'image_size': 384, 'batch_size': 96, 'init_lr': 1e-05, 'epochs': 15, 'mixup': True, 'ema_decay': 0.995, 'epochs_for_final_submission': 4}\n",
      "****************************** Fold 0 ******************************\n",
      "100%|█████████████████████████████████████████| 870/870 [00:10<00:00, 83.25it/s]\n",
      "Fold 0 | auc_score 0.8556\n",
      "****************************** Fold 1 ******************************\n",
      "100%|█████████████████████████████████████████| 870/870 [00:09<00:00, 92.98it/s]\n",
      "Fold 1 | auc_score 0.8572\n",
      "****************************** Fold 2 ******************************\n",
      "100%|█████████████████████████████████████████| 869/869 [00:09<00:00, 89.64it/s]\n",
      "Fold 2 | auc_score 0.8492\n",
      "****************************** Fold 3 ******************************\n",
      "100%|█████████████████████████████████████████| 870/870 [00:10<00:00, 86.69it/s]\n",
      "Fold 3 | auc_score 0.8549\n",
      "****************************** Fold 4 ******************************\n",
      "100%|█████████████████████████████████████████| 869/869 [00:11<00:00, 76.71it/s]\n",
      "Fold 4 | auc_score 0.8428\n",
      "OOF | auc_score 0.8491\n"
     ]
    }
   ],
   "source": [
    "!python eval_5folds.py --cfg configs/vit_large_384.yaml     ### for label cleaning in exp4 and exp5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83293566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cfg='configs/eva_large_384.yaml', ckpt_dir='checkpoints', frac=1, folds=[0, 1, 2, 3, 4])\n",
      "{'model_name': 'eva_large_patch14_336.in22k_ft_in22k_in1k', 'workers': 8, 'image_size': 384, 'batch_size': 96, 'init_lr': 1e-05, 'epochs': 15, 'mixup': True, 'ema_decay': 0.995, 'epochs_for_final_submission': 10}\n",
      "****************************** Fold 0 ******************************\n",
      "TRAIN: 441842 | VALID: 209746\n",
      "Fold: 0 | Epoch 0 | train loss: 0.01758 | val_auc: 0.79731 | ema_val_auc: 0.80417\n",
      "val auc improved from 0.00000 to 0.80417 saving model to checkpoints/eva_large_patch14_336.in22k_ft_in22k_in1k_384_fold0.pt\n",
      "Fold: 0 | Epoch 1 | train loss: 0.01323 | val_auc: 0.82433 | ema_val_auc: 0.84108\n",
      "val auc improved from 0.80417 to 0.84108 saving model to checkpoints/eva_large_patch14_336.in22k_ft_in22k_in1k_384_fold0.pt\n",
      "Fold: 0 | Epoch 2 | train loss: 0.01108 | val_auc: 0.83535 | ema_val_auc: 0.85388\n",
      "val auc improved from 0.84108 to 0.85388 saving model to checkpoints/eva_large_patch14_336.in22k_ft_in22k_in1k_384_fold0.pt\n",
      "Fold: 0 | Epoch 3 | train loss: 0.00960 | val_auc: 0.83283 | ema_val_auc: 0.84582\n",
      "Fold: 0 | Epoch 4 | train loss: 0.00829 | val_auc: 0.83596 | ema_val_auc: 0.84570\n",
      "Fold: 0 | Epoch 5 | train loss: 0.00725 | val_auc: 0.82808 | ema_val_auc: 0.83794\n",
      "Fold: 0 | Epoch 6 | train loss: 0.00653 | val_auc: 0.82832 | ema_val_auc: 0.83162\n",
      "Fold: 0 | Epoch 7 | train loss: 0.00581 | val_auc: 0.82857 | ema_val_auc: 0.83931\n",
      "Fold: 0 | Epoch 8 | train loss: 0.00509 | val_auc: 0.82882 | ema_val_auc: 0.84700\n",
      "Fold: 0 | Epoch 9 | train loss: 0.00437 | val_auc: 0.82907 | ema_val_auc: 0.85336\n",
      "Fold: 0 | Epoch 10 | train loss: 0.00365 | val_auc: 0.82932 | ema_val_auc: 0.85301\n",
      "Fold: 0 | Epoch 11 | train loss: 0.00293 | val_auc: 0.82957 | ema_val_auc: 0.84981\n",
      "Fold: 0 | Epoch 12 | train loss: 0.00221 | val_auc: 0.82982 | ema_val_auc: 0.85280\n",
      "Fold: 0 | Epoch 13 | train loss: 0.00149 | val_auc: 0.83007 | ema_val_auc: 0.84487\n",
      "Fold: 0 | Epoch 14 | train loss: 0.00077 | val_auc: 0.83032 | ema_val_auc: 0.85350\n",
      "****************************** Fold 1 ******************************\n",
      "TRAIN: 453316 | VALID: 198113\n",
      "Fold: 1 | Epoch 0 | train loss: 0.01675 | val_auc: 0.80292 | ema_val_auc: 0.81806\n",
      "val auc improved from 0.00000 to 0.81806 saving model to checkpoints/eva_large_patch14_336.in22k_ft_in22k_in1k_384_fold1.pt\n",
      "Fold: 1 | Epoch 1 | train loss: 0.01246 | val_auc: 0.83864 | ema_val_auc: 0.84676\n",
      "val auc improved from 0.81806 to 0.84676 saving model to checkpoints/eva_large_patch14_336.in22k_ft_in22k_in1k_384_fold1.pt\n",
      "Fold: 1 | Epoch 2 | train loss: 0.01061 | val_auc: 0.84316 | ema_val_auc: 0.85503\n",
      "val auc improved from 0.84676 to 0.85503 saving model to checkpoints/eva_large_patch14_336.in22k_ft_in22k_in1k_384_fold1.pt\n",
      "Fold: 1 | Epoch 3 | train loss: 0.00905 | val_auc: 0.85446 | ema_val_auc: 0.86254\n",
      "val auc improved from 0.85503 to 0.86254 saving model to checkpoints/eva_large_patch14_336.in22k_ft_in22k_in1k_384_fold1.pt\n",
      "Fold: 1 | Epoch 4 | train loss: 0.00776 | val_auc: 0.84877 | ema_val_auc: 0.85839\n",
      "Fold: 1 | Epoch 5 | train loss: 0.00680 | val_auc: 0.84402 | ema_val_auc: 0.85311\n",
      "Fold: 1 | Epoch 6 | train loss: 0.00614 | val_auc: 0.83888 | ema_val_auc: 0.85037\n",
      "Fold: 1 | Epoch 7 | train loss: 0.00554 | val_auc: 0.84569 | ema_val_auc: 0.85049\n",
      "Fold: 1 | Epoch 8 | train loss: 0.00501 | val_auc: 0.84990 | ema_val_auc: 0.85527\n",
      "Fold: 1 | Epoch 9 | train loss: 0.00475 | val_auc: 0.83928 | ema_val_auc: 0.84576\n",
      "Fold: 1 | Epoch 10 | train loss: 0.00449 | val_auc: 0.82866 | ema_val_auc: 0.83625\n",
      "Fold: 1 | Epoch 11 | train loss: 0.00423 | val_auc: 0.81804 | ema_val_auc: 0.82674\n",
      "Fold: 1 | Epoch 12 | train loss: 0.00397 | val_auc: 0.80742 | ema_val_auc: 0.81723\n",
      "Fold: 1 | Epoch 13 | train loss: 0.00371 | val_auc: 0.79680 | ema_val_auc: 0.80772\n",
      "Fold: 1 | Epoch 14 | train loss: 0.00345 | val_auc: 0.78618 | ema_val_auc: 0.79821\n",
      "****************************** Fold 2 ******************************\n",
      "TRAIN: 441186 | VALID: 203375\n",
      "Fold: 2 | Epoch 0 | train loss: 0.01760 | val_auc: 0.78830 | ema_val_auc: 0.79870\n",
      "val auc improved from 0.00000 to 0.79870 saving model to checkpoints/eva_large_patch14_336.in22k_ft_in22k_in1k_384_fold2.pt\n",
      "Fold: 2 | Epoch 1 | train loss: 0.01331 | val_auc: 0.82945 | ema_val_auc: 0.83758\n",
      "val auc improved from 0.79870 to 0.83758 saving model to checkpoints/eva_large_patch14_336.in22k_ft_in22k_in1k_384_fold2.pt\n",
      "Fold: 2 | Epoch 2 | train loss: 0.01118 | val_auc: 0.83867 | ema_val_auc: 0.84268\n",
      "val auc improved from 0.83758 to 0.84268 saving model to checkpoints/eva_large_patch14_336.in22k_ft_in22k_in1k_384_fold2.pt\n",
      "Fold: 2 | Epoch 3 | train loss: 0.00949 | val_auc: 0.83886 | ema_val_auc: 0.84838\n",
      "val auc improved from 0.84268 to 0.84838 saving model to checkpoints/eva_large_patch14_336.in22k_ft_in22k_in1k_384_fold2.pt\n",
      "Fold: 2 | Epoch 4 | train loss: 0.00821 | val_auc: 0.83853 | ema_val_auc: 0.84725\n",
      "Fold: 2 | Epoch 5 | train loss: 0.00727 | val_auc: 0.83627 | ema_val_auc: 0.84282\n",
      "Fold: 2 | Epoch 6 | train loss: 0.00648 | val_auc: 0.82449 | ema_val_auc: 0.83972\n",
      "Fold: 2 | Epoch 7 | train loss: 0.00578 | val_auc: 0.84345 | ema_val_auc: 0.83902\n",
      "Fold: 2 | Epoch 8 | train loss: 0.00540 | val_auc: 0.82664 | ema_val_auc: 0.83806\n",
      "Fold: 2 | Epoch 9 | train loss: 0.00494 | val_auc: 0.84193 | ema_val_auc: 0.84363\n",
      "Fold: 2 | Epoch 10 | train loss: 0.00478 | val_auc: 0.83872 | ema_val_auc: 0.84129\n",
      "Fold: 2 | Epoch 11 | train loss: 0.00464 | val_auc: 0.83980 | ema_val_auc: 0.84019\n",
      "Fold: 2 | Epoch 12 | train loss: 0.00459 | val_auc: 0.84107 | ema_val_auc: 0.84126\n",
      "Fold: 2 | Epoch 13 | train loss: 0.00465 | val_auc: 0.84107 | ema_val_auc: 0.84115\n",
      "Fold: 2 | Epoch 14 | train loss: 0.00437 | val_auc: 0.83919 | ema_val_auc: 0.83967\n",
      "****************************** Fold 3 ******************************\n",
      "TRAIN: 443849 | VALID: 207682\n",
      "Fold: 3 | Epoch 0 | train loss: 0.01728 | val_auc: 0.79934 | ema_val_auc: 0.80599\n",
      "val auc improved from 0.00000 to 0.80599 saving model to checkpoints/eva_large_patch14_336.in22k_ft_in22k_in1k_384_fold3.pt\n",
      "Fold: 3 | Epoch 1 | train loss: 0.01297 | val_auc: 0.82772 | ema_val_auc: 0.83948\n",
      "val auc improved from 0.80599 to 0.83948 saving model to checkpoints/eva_large_patch14_336.in22k_ft_in22k_in1k_384_fold3.pt\n",
      "Fold: 3 | Epoch 2 | train loss: 0.01102 | val_auc: 0.83701 | ema_val_auc: 0.84968\n",
      "val auc improved from 0.83948 to 0.84968 saving model to checkpoints/eva_large_patch14_336.in22k_ft_in22k_in1k_384_fold3.pt\n",
      "Fold: 3 | Epoch 3 | train loss: 0.00940 | val_auc: 0.82667 | ema_val_auc: 0.84716\n",
      "Fold: 3 | Epoch 4 | train loss: 0.00793 | val_auc: 0.83996 | ema_val_auc: 0.84336\n",
      "Fold: 3 | Epoch 5 | train loss: 0.00714 | val_auc: 0.84819 | ema_val_auc: 0.85090\n",
      "val auc improved from 0.84968 to 0.85090 saving model to checkpoints/eva_large_patch14_336.in22k_ft_in22k_in1k_384_fold3.pt\n",
      "Fold: 3 | Epoch 6 | train loss: 0.00642 | val_auc: 0.83385 | ema_val_auc: 0.83843\n",
      "Fold: 3 | Epoch 7 | train loss: 0.00573 | val_auc: 0.83942 | ema_val_auc: 0.84445\n",
      "Fold: 3 | Epoch 8 | train loss: 0.00537 | val_auc: 0.83743 | ema_val_auc: 0.83375\n",
      "Fold: 3 | Epoch 9 | train loss: 0.00506 | val_auc: 0.83343 | ema_val_auc: 0.83883\n",
      "Fold: 3 | Epoch 10 | train loss: 0.00466 | val_auc: 0.83823 | ema_val_auc: 0.84009\n",
      "Fold: 3 | Epoch 11 | train loss: 0.00450 | val_auc: 0.84290 | ema_val_auc: 0.84231\n",
      "Fold: 3 | Epoch 12 | train loss: 0.00448 | val_auc: 0.84149 | ema_val_auc: 0.84168\n",
      "Fold: 3 | Epoch 13 | train loss: 0.00449 | val_auc: 0.84149 | ema_val_auc: 0.84153\n",
      "Fold: 3 | Epoch 14 | train loss: 0.00440 | val_auc: 0.84125 | ema_val_auc: 0.84127\n",
      "****************************** Fold 4 ******************************\n",
      "TRAIN: 439595 | VALID: 209895\n",
      "Fold: 4 | Epoch 0 | train loss: 0.01763 | val_auc: 0.77953 | ema_val_auc: 0.79327\n",
      "val auc improved from 0.00000 to 0.79327 saving model to checkpoints/eva_large_patch14_336.in22k_ft_in22k_in1k_384_fold4.pt\n",
      "Fold: 4 | Epoch 1 | train loss: 0.01307 | val_auc: 0.81374 | ema_val_auc: 0.81689\n",
      "val auc improved from 0.79327 to 0.81689 saving model to checkpoints/eva_large_patch14_336.in22k_ft_in22k_in1k_384_fold4.pt\n",
      "Fold: 4 | Epoch 2 | train loss: 0.01124 | val_auc: 0.82549 | ema_val_auc: 0.83213\n",
      "val auc improved from 0.81689 to 0.83213 saving model to checkpoints/eva_large_patch14_336.in22k_ft_in22k_in1k_384_fold4.pt\n",
      "Fold: 4 | Epoch 3 | train loss: 0.00963 | val_auc: 0.83239 | ema_val_auc: 0.83470\n",
      "val auc improved from 0.83213 to 0.83470 saving model to checkpoints/eva_large_patch14_336.in22k_ft_in22k_in1k_384_fold4.pt\n",
      "Fold: 4 | Epoch 4 | train loss: 0.00816 | val_auc: 0.83307 | ema_val_auc: 0.83530\n",
      "val auc improved from 0.83470 to 0.83530 saving model to checkpoints/eva_large_patch14_336.in22k_ft_in22k_in1k_384_fold4.pt\n",
      "Fold: 4 | Epoch 5 | train loss: 0.00726 | val_auc: 0.82492 | ema_val_auc: 0.83131\n",
      "Fold: 4 | Epoch 6 | train loss: 0.00659 | val_auc: 0.82923 | ema_val_auc: 0.83022\n",
      "Fold: 4 | Epoch 7 | train loss: 0.00586 | val_auc: 0.82764 | ema_val_auc: 0.83282\n",
      "Fold: 4 | Epoch 8 | train loss: 0.00541 | val_auc: 0.83030 | ema_val_auc: 0.83075\n",
      "Fold: 4 | Epoch 9 | train loss: 0.00512 | val_auc: 0.82756 | ema_val_auc: 0.83356\n",
      "Fold: 4 | Epoch 10 | train loss: 0.00480 | val_auc: 0.83060 | ema_val_auc: 0.83239\n",
      "Fold: 4 | Epoch 11 | train loss: 0.00464 | val_auc: 0.83306 | ema_val_auc: 0.83471\n",
      "Fold: 4 | Epoch 12 | train loss: 0.00448 | val_auc: 0.82994 | ema_val_auc: 0.83198\n",
      "Fold: 4 | Epoch 13 | train loss: 0.00432 | val_auc: 0.82678 | ema_val_auc: 0.83370\n",
      "Fold: 4 | Epoch 14 | train loss: 0.00416 | val_auc: 0.83193 | ema_val_auc: 0.83196\n"
     ]
    }
   ],
   "source": [
    "!python train_5folds.py --cfg configs/eva_large_384.yaml    ### for label cleaning in exp4 and exp5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51e67187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cfg='configs/eva_large_384.yaml', ckpt_dir='checkpoints', folds=[0, 1, 2, 3, 4], pred_dir='predictions', crop_ratio=1, hflip=False)\n",
      "{'model_name': 'eva_large_patch14_336.in22k_ft_in22k_in1k', 'workers': 8, 'image_size': 384, 'batch_size': 96, 'init_lr': 1e-05, 'epochs': 15, 'mixup': True, 'ema_decay': 0.995, 'epochs_for_final_submission': 10}\n",
      "****************************** Fold 0 ******************************\n",
      "100%|█████████████████████████████████████████| 870/870 [00:09<00:00, 89.05it/s]\n",
      "Fold 0 | auc_score 0.8539\n",
      "****************************** Fold 1 ******************************\n",
      "100%|█████████████████████████████████████████| 870/870 [00:09<00:00, 91.37it/s]\n",
      "Fold 1 | auc_score 0.8625\n",
      "****************************** Fold 2 ******************************\n",
      "100%|█████████████████████████████████████████| 869/869 [00:09<00:00, 89.58it/s]\n",
      "Fold 2 | auc_score 0.8484\n",
      "****************************** Fold 3 ******************************\n",
      "100%|█████████████████████████████████████████| 870/870 [00:10<00:00, 83.18it/s]\n",
      "Fold 3 | auc_score 0.8509\n",
      "****************************** Fold 4 ******************************\n",
      "100%|█████████████████████████████████████████| 869/869 [00:10<00:00, 86.86it/s]\n",
      "Fold 4 | auc_score 0.8353\n",
      "OOF | auc_score 0.8486\n"
     ]
    }
   ],
   "source": [
    "!python eval_5folds.py --cfg configs/eva_large_384.yaml     ### for label cleaning in exp4 and exp5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25e1431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Due to time constraints, I couldn't use 5 models (5 folds) for prediction. \n",
    "### I could only use a single model trained on almost the full dataset, using only 50 series for evaluation, and selecting the best epoch based on the public leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81b12a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cfg='configs/vit_large_384.yaml', ckpt_dir='checkpoints', frac=1)\n",
      "{'model_name': 'vit_large_patch14_clip_336.openai_ft_in12k_in1k', 'workers': 8, 'image_size': 384, 'batch_size': 96, 'init_lr': 1e-05, 'epochs': 15, 'mixup': True, 'ema_decay': 0.995, 'epochs_for_final_submission': 4}\n",
      "TRAIN: 542801 | VALID: 23181\n",
      "Epoch 0 | train loss: 0.01751 | ema_val_auc: 0.79868\n",
      "Epoch 1 | train loss: 0.01368 | ema_val_auc: 0.82559\n",
      "Epoch 2 | train loss: 0.01191 | ema_val_auc: 0.85952\n",
      "Epoch 3 | train loss: 0.01035 | ema_val_auc: 0.86603\n",
      "Epoch 4 | train loss: 0.00881 | ema_val_auc: 0.86144\n",
      "Epoch 5 | train loss: 0.00760 | ema_val_auc: 0.85874\n",
      "Epoch 6 | train loss: 0.00665 | ema_val_auc: 0.87011\n",
      "Epoch 7 | train loss: 0.00572 | ema_val_auc: 0.86839\n",
      "Epoch 8 | train loss: 0.00513 | ema_val_auc: 0.87125\n",
      "Epoch 9 | train loss: 0.00474 | ema_val_auc: 0.87239\n",
      "Epoch 10 | train loss: 0.00438 | ema_val_auc: 0.86948\n",
      "Epoch 11 | train loss: 0.00419 | ema_val_auc: 0.87076\n",
      "Epoch 12 | train loss: 0.00407 | ema_val_auc: 0.87335\n",
      "Epoch 13 | train loss: 0.00400 | ema_val_auc: 0.87378\n",
      "Epoch 14 | train loss: 0.00393 | ema_val_auc: 0.87421\n"
     ]
    }
   ],
   "source": [
    "!python train.py --cfg configs/vit_large_384.yaml           ### for final_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bbed502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cfg='configs/eva_large_384.yaml', ckpt_dir='checkpoints', frac=1)\n",
      "{'model_name': 'eva_large_patch14_336.in22k_ft_in22k_in1k', 'workers': 8, 'image_size': 384, 'batch_size': 96, 'init_lr': 1e-05, 'epochs': 15, 'mixup': True, 'ema_decay': 0.995, 'epochs_for_final_submission': 10}\n",
      "TRAIN: 542801 | VALID: 23181\n",
      "Epoch 0 | train loss: 0.01681 | ema_val_auc: 0.81607\n",
      "Epoch 1 | train loss: 0.01272 | ema_val_auc: 0.83645\n",
      "Epoch 2 | train loss: 0.01073 | ema_val_auc: 0.85156\n",
      "Epoch 3 | train loss: 0.00917 | ema_val_auc: 0.82809\n",
      "Epoch 4 | train loss: 0.00795 | ema_val_auc: 0.83048\n",
      "Epoch 5 | train loss: 0.00696 | ema_val_auc: 0.81295\n",
      "Epoch 6 | train loss: 0.00627 | ema_val_auc: 0.82893\n",
      "Epoch 7 | train loss: 0.00574 | ema_val_auc: 0.82776\n",
      "Epoch 8 | train loss: 0.00523 | ema_val_auc: 0.83465\n",
      "Epoch 9 | train loss: 0.00495 | ema_val_auc: 0.82652\n",
      "Epoch 10 | train loss: 0.00459 | ema_val_auc: 0.82367\n",
      "Epoch 11 | train loss: 0.00423 | ema_val_auc: 0.82082\n",
      "Epoch 12 | train loss: 0.00387 | ema_val_auc: 0.81797\n",
      "Epoch 13 | train loss: 0.00351 | ema_val_auc: 0.81512\n",
      "Epoch 14 | train loss: 0.00315 | ema_val_auc: 0.81227\n"
     ]
    }
   ],
   "source": [
    "!python train.py --cfg configs/eva_large_384.yaml           ### for final_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37362694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cfg='configs/vit_large_384.yaml', ckpt_dir='checkpoints', pred_dir='predictions', folds=[0, 1, 2, 3, 4])\n",
      "{'model_name': 'vit_large_patch14_clip_336.openai_ft_in12k_in1k', 'workers': 8, 'image_size': 384, 'batch_size': 96, 'init_lr': 1e-05, 'epochs': 15, 'mixup': True, 'ema_decay': 0.995, 'epochs_for_final_submission': 4}\n",
      "Lausanne_TOFMRA | Test size: 43800\n",
      "100%|█████████████████████████████████████████| 457/457 [05:39<00:00,  1.35it/s]\n",
      "Royal_Brisbane_TOFMRA | Test size: 9433\n",
      "100%|███████████████████████████████████████████| 99/99 [01:13<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "!python predict_external_dataset.py --cfg configs/vit_large_384.yaml  ### predict on external dataset (Lausanne_TOFMRA + Royal_Brisbane_TOFMRA) to create pseudo-labeling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
